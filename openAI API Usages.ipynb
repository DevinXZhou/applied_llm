{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53333fa8-594a-458b-be96-796c5982a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# use your own openai api key\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "print(openai.__version__)\n",
    "\n",
    "client = OpenAI(api_key = openai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10757db8-abeb-4f8f-8451-78dc191df217",
   "metadata": {},
   "source": [
    "## Create Chatbot Davis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ed74bb-9cf0-4dc9-a7ae-2c35701bf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the system and setup up message stack to track conversation\n",
    "system_msg = {\"role\": \"system\", \"content\": \"You are a helpful assistant whose name is Davis.\"}\n",
    "message_records = [system_msg]\n",
    "\n",
    "config = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "def get_response(user_message, config):\n",
    "    # input message is always from user\n",
    "    new_msg = {\"role\": \"user\", \"content\": user_message}\n",
    "    # stacking the user message to track the conversation\n",
    "    message_records.append(new_msg)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        messages=message_records,\n",
    "        **config,\n",
    "    )\n",
    "    response_msg  = response.choices[0].message.content\n",
    "    assistant_msg = {\"role\": \"assistant\", \"content\": response_msg}\n",
    "    # stacking the AI responded message to track the conversation\n",
    "    message_records.append(assistant_msg)\n",
    "    print(response_msg)\n",
    "    return response_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a4ce50-eb6a-4a01-87a8-17a6c47ae8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is Davis. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"Hi! what is your name?\"\n",
    "_ = get_response(user_msg, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f15ce4-2723-4b0a-9a0a-f5340631b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI is bringing back its team focused on robotics and intends to create a specialized artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"Help me paraphrase this sentence ```OpenAI revives its robotic research team, plans to build dedicated AI```\"\n",
    "_ = get_response(user_msg, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17592f88-83bd-4746-b0f1-2609d6a73049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked me to help you paraphrase the sentence \"OpenAI revives its robotic research team, plans to build dedicated AI.\"\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"Hi! what did I ask you?\"\n",
    "_ = get_response(user_msg, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328dcf5-4a59-43a1-8057-403d0d475f3c",
   "metadata": {},
   "source": [
    "## Give Davis Tools to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5eacfa5-6715-4a2f-a262-47ba7f00b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the get weather tool schema\n",
    "tool_schema = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"location\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "        },\n",
    "        \"unit\": {\n",
    "          \"type\": \"string\",\n",
    "          \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"location\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "# write a python function get_weather for chatbot to call\n",
    "import python_weather\n",
    "import asyncio\n",
    "\n",
    "async def get_weather(location, unit):\n",
    "    degree_unit = python_weather.METRIC if unit == \"celsius\" else python_weather.IMPERIAL\n",
    "    u = \"°C\" if unit == \"celsius\" else \"°F\"\n",
    "    client = python_weather.Client(unit=degree_unit)\n",
    "    weather = await client.get(location)\n",
    "    weather_context = f\"Current weather in {city}: {weather.temperature} {u}\"\n",
    "    await client.close()\n",
    "    return weather_context\n",
    "\n",
    "tools = [tool_schema]\n",
    "tool_mapper = {\"get_current_weather\": get_weather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d26274-1469-4974-8b40-736255fb67f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current weather in San Francisco: 56 °F\n"
     ]
    }
   ],
   "source": [
    "# validate if the tool works\n",
    "city = \"San Francisco\"\n",
    "c = await get_weather(city, \"fahrenheit\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5244c4-7b70-4304-9722-756ac8aa0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "system_msg = {\"role\": \"system\", \"content\": \"You are a helpful assistant whose name is Davis.\"}\n",
    "message_records = [system_msg]\n",
    "\n",
    "config = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "def query(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        **config,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def query_with_tools(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        tools = tools,\n",
    "        tool_choice = 'auto',\n",
    "        **config,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "async def call_tool(response):\n",
    "    tool_name = response.choices[0].message.tool_calls[0].function.name\n",
    "    args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    print(f\"Using tool `{tool_name}` with args: {args} \")\n",
    "    assert tool_name in tool_mapper\n",
    "    function = tool_mapper[tool_name]\n",
    "    result = await function(**args)\n",
    "    # append new system message to get more context that was generated by using tool\n",
    "    sys_msg = {\"role\": \"system\", \"content\": result}\n",
    "    message_records.append(sys_msg)\n",
    "    print(f\"Fetched tool result: {result}\")\n",
    "   \n",
    "\n",
    "async def act(user_message, config, tools):\n",
    "    # input message is always from user\n",
    "    new_msg = {\"role\": \"user\", \"content\": user_message}\n",
    "    # stacking the user message to track the conversation\n",
    "    message_records.append(new_msg)\n",
    "\n",
    "    # check if any tools are needed to be used\n",
    "    response = query_with_tools(message_records)\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    if tool_calls is not None and len(tool_calls) > 0:\n",
    "        await call_tool(response)\n",
    "        # since tools are already used, then query without tools generate better promising results\n",
    "        response = query(message_records)\n",
    "\n",
    "    # now get final response message\n",
    "    response_msg  = response.choices[0].message.content\n",
    "    assistant_msg = {\"role\": \"assistant\", \"content\": response_msg}\n",
    "    # stacking the AI responded message to track the conversation\n",
    "    message_records.append(assistant_msg)\n",
    "    return response_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae064f7-f2a0-4411-824f-799ed7a4486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tool `get_current_weather` with args: {'location': 'San Francisco', 'unit': 'celsius'} \n",
      "Fetched tool result: Current weather in San Francisco: 13 °C\n",
      "The weather in San Francisco today is 13°C. It seems to be a bit cool there. Do you need any more information about the weather or anything else?\n"
     ]
    }
   ],
   "source": [
    "# gonna use weather tool\n",
    "res = await act(\"how is the weather in San Francisco today?\", config, tools)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba98655-43de-404c-9985-b7e5f64c162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One fun thing to do in San Francisco today is to visit the Golden Gate Park. You can explore the beautiful gardens, visit the California Academy of Sciences, rent a paddleboat on Stow Lake, or simply enjoy a leisurely walk in the park. It's a great way to spend a relaxing day in the city. Enjoy your time in San Francisco!\n"
     ]
    }
   ],
   "source": [
    "# will not use any tools\n",
    "res = await act(\"Suggest me one fun thing to do in San Francisco today?\", config, tools)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71e50e-8f5a-49ba-b415-7c4feaecc610",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be4ebcbc-b929-48e1-ab77-e6ef48564d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity score of two sentences using openAI embeddings\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "Available Embedding Models\n",
    "MODEL\t              \tMAX_INPUT  OUTPUT\n",
    "text-embedding-3-small\t8191       1536\n",
    "text-embedding-3-large\t8191       3072\n",
    "text-embedding-ada-002\t8191       1536\n",
    "\"\"\"\n",
    "\n",
    "# Transform texts to feature vectors\n",
    "texts = [\n",
    "    \"def add(a, b): return a + b\", \n",
    "    \"def min(a, b): return a - b\", \n",
    "    \"The quick brown fox jumps over a lazy dog\"]\n",
    "\n",
    "def get_embeddings(texts: List[str], model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input = texts, model=model)\n",
    "   \n",
    "    vectors = np.array([d.embedding for d in response.data])\n",
    "    return vectors\n",
    "\n",
    "\n",
    "vs = get_embeddings(texts)\n",
    "print(len(vs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89bfee84-2d11-4a5c-8e15-fd4a4fbc752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161033277308834"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~1 higher score means more similar\n",
    "np.dot(vs[0], vs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76aea404-2ca5-45fa-ba7c-991a5e0b4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10385193973303869"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(vs[1], vs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bbcfb2d-9d98-42be-a28c-a9dd42e911e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[755, 923, 2948, 11, 293, 1680, 471, 264, 489, 293]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Count number of tokens to prevent context overflow\n",
    "import tiktoken\n",
    "\"\"\"\n",
    "Encoders:\n",
    "GPT-4 is using cl100k_base \n",
    "GPT-4o is using o200k_base, not public available\n",
    "\"\"\"\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = encoding.encode(texts[0])\n",
    "\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74dc03-6137-4aa8-87fd-18a299b152a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
